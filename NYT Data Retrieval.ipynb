{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import threading\n",
    "import time\n",
    "from os import environ\n",
    "from flask import Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "url =  \"https://api.nytimes.com/svc/search/v2/articlesearch.json\"\n",
    "api_key = \"2ba396b683c14b46a152eb84639c6d3a\"\n",
    "q = \"36 hours\"\n",
    "params = {\"api-key\": api_key,\n",
    "    \"q\": q\n",
    "}\n",
    "response = requests.get(url, params=params)\n",
    "json_data = response.json()\n",
    "urls = []\n",
    "# Parsing the json data\n",
    "docs = json_data['response']['docs']\n",
    "for d in docs:\n",
    "    urls.append(d['web_url'])\n",
    "print(len(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created the files\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re\n",
    "def find_text(url):\n",
    "        reviews = {}\n",
    "        response = requests.get(url)\n",
    "        content = response.content\n",
    "        parser = BeautifulSoup(content, 'html.parser')\n",
    "        title = parser.find(\"head\").title.text\n",
    "        names = parser.find_all(\"div\", class_=\"listy_body\")\n",
    "        for n in names[1:]:\n",
    "            heads = n.find_all(\"h3\") \n",
    "            paras = n.find_all(\"p\")\n",
    "            for h,ps in zip(heads, paras):\n",
    "                h = h.text.split(\") \")[1]\n",
    "                r = ps.text\n",
    "                reviews[h] = r\n",
    "        return reviews, title\n",
    "    \n",
    "for u in urls:\n",
    "    reviews, title = find_text(u)\n",
    "    with open(title+\".csv\", \"w\") as file:\n",
    "        w = csv.writer(file)\n",
    "        w.writerows(reviews.items())\n",
    "            \n",
    "print(\"Created the files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Activity  \\\n",
      "0             7 P.M. Fresh Seafood   \n",
      "1       1 P.M. Hedonistic Farewell   \n",
      "2  8 P.M. Where the Mango Crumbles   \n",
      "3      4 P.M. Balinese Culture 101   \n",
      "4         Noon. Lunch on the Beach   \n",
      "\n",
      "                                         Description  \n",
      "0  Set in a tranquil garden uphill from P.V.G., R...  \n",
      "1  Treat yourself to a lazy afternoon of brunch a...  \n",
      "2  Komang John’s Café, at the Blue Moon Villas re...  \n",
      "3  Visitors in search of an unfiltered, uncommerc...  \n",
      "4  For a bit of seaside R & R, head to Amed, a co...  \n",
      "11\n"
     ]
    }
   ],
   "source": [
    "# Reading the csv files and prediciting the ratings\n",
    "bali_data = pd.read_csv(\"36 Hours in Bali - The New York Times.csv\", names=['Activity', 'Description'])\n",
    "baltimore_data = pd.read_csv(\"36 Hours in Baltimore - The New York Times.csv\", names=['Activity', 'Description'])\n",
    "cyprus_data = pd.read_csv(\"36 Hours in Cyprus - The New York Times.csv\", names=['Activity', 'Description'])\n",
    "fez_data = pd.read_csv(\"36 Hours in Fez, Morocco - The New York Times.csv\", names=['Activity', 'Description'])\n",
    "tokyo_data = pd.read_csv(\"36 Hours in Tokyo - The New York Times.csv\", names=['Activity', 'Description'])\n",
    "print(bali_data.head())\n",
    "print(bali_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "print(tokyo_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
